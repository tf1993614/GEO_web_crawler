{"metadata":{"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install lxml","metadata":{"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: Invalid requirement: 'lxml,BeautifulSoup4'\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"id":"b81ad6fe-6d97-4fa0-bea1-7751f6e04ba1"},{"cell_type":"code","source":"pip install BeautifulSoup4","metadata":{"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting BeautifulSoup4\n  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n     |████████████████████████████████| 128 kB 4.6 MB/s            \n\u001b[?25hCollecting soupsieve>1.2\n  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\nInstalling collected packages: soupsieve, BeautifulSoup4\nSuccessfully installed BeautifulSoup4-4.11.1 soupsieve-2.3.2.post1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"id":"3e145bdf-618e-4cfa-9977-8ab5a358dee4"},{"cell_type":"code","source":"import time\nfrom csv import DictWriter\nfrom threading import Thread\nfrom concurrent.futures import ThreadPoolExecutor\nfrom multiprocessing import Queue, Process\nimport os\nimport sys\nimport re\n\nimport requests\nimport lxml\nfrom lxml import etree\nfrom bs4 import BeautifulSoup","metadata":{"trusted":true},"execution_count":41,"outputs":[],"id":"be0281f3-14e3-420a-a5a3-dd4cbf60953e"},{"cell_type":"code","source":"class GEO_crawler:\n    def __init__(self, GEO_id):\n        self.GEO_id = GEO_id\n        self.base_url = \"https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi\"\n        \n    def progress_bar(self, num, total):\n        rate = float(num)/total\n        #print(\"rate:%s\"%rate)\n        ratenum = int(rate * 100)\n        #print(ratenum)\n        \n        show = \"\\r[{}{}]{}\".format(\"*\" * ratenum, \"-\" * (total - ratenum), str(ratenum) + \"%\")\n        \n        if ratenum == 100:\n            sys.stdout.write(show)\n            sys.stdout.write(\"\\n{} is over\\n\".format(self.GEO_id))\n        else:\n            sys.stdout.write(show)\n            sys.stdout.flush()\n        \n        \n        \n    def item2csv(self, item):\n       \n            has_header = os.path.exists(self.GEO_id+\".csv\")\n\n            with open(self.GEO_id +\".csv\", \"a\") as file:\n                writer = DictWriter(file, list(item.keys()))\n                if not has_header:\n                    writer.writeheader()\n                    has_header = True\n\n                writer.writerow(item)\n        \n    def download(self):\n        resp = requests.get(self.base_url, params={\"acc\": self.GEO_id})\n        if resp.status_code == 200:\n            resp.encoding = \"utf-8\"\n            self.parse(resp.text)\n    \n    def parse(self, html):\n        root = BeautifulSoup(html, \"lxml\")\n        sites = root.select(\"a\")\n        \n        url_ls = []\n        \n        number = 1\n        total = 0\n        \n        for site in sites:\n            text = site.get_text()\n            if re.findall(\"^GSM[0-9]+\", text):\n                total +=1\n        \n        for site in sites:\n            text = site.get_text()\n            if text.startswith(\"GSM\"):\n                resp = requests.get(self.base_url, params={\"acc\": text})\n                if resp.status_code == 200:\n                    resp.encoding = \"utf-8\"\n                    \n                    root = BeautifulSoup(resp.text, \"lxml\")\n                    tags = root.select(\"tr[valign = top]\")\n                    \n                    item = {}\n                    for num,tag in enumerate(tags):\n                        if num == 0:\n                            continue\n                        else:\n                            tag_ls = tag.select(\"td\")\n                            \n                            if len(tag_ls) > 1:\n                                if tag_ls[0].get_text() != \"\\xa0\":\n                                    item[tag_ls[0].get_text()] = tag_ls[1].get_text()\n                            # else:\n                            #     if tag_ls[0].get_text() != \"\\xa0\":\n                            #         text_ls = []\n                            #         for i in range(len(tag_ls)):\n                            #             text_ls.append(tag_ls[i].get_text())\n                            #         item[text_ls[0]] = \n                    \n                    #print(item)\n                    self.item2csv(item)\n                    self.progress_bar(num = number, total = total)\n                    number += 1\n    \n                \n                \n            ","metadata":{"trusted":true},"execution_count":83,"outputs":[],"id":"47176b52-abd4-4cd8-88fb-6cb72f8ebc1a"},{"cell_type":"code","source":"a = GEO_crawler(\"GSE201369\")\na.download()","metadata":{"tags":[],"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"[****************************************************************************************************]100%\nGSE201369 is over\n","output_type":"stream"}],"id":"d687d769-c0d6-4bb2-b611-972d4c1061f5"},{"cell_type":"code","source":"def main(max_workers = 4, GEO_id_ls = None):\n    with ThreadPoolExecutor(max_workers=max_workers) as pool:\n        start = time.time()\n        for GEO_id in GEO_id_ls:\n            if os.path.exists(GEO_id + \".csv\"):\n                os.remove(GEO_id + \".csv\")\n            pool.submit(GEO_crawler(GEO_id).download)\n    end = time.time()\n    print(f\"consuming: {end -start:.3f} seconds\")","metadata":{"trusted":true},"execution_count":86,"outputs":[],"id":"98b51ec9-948e-45f8-8e5b-2386c4d3324f"},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    main(GEO_id_ls=[\"GSE201369\", \"GSE44801\"])","metadata":{"trusted":true},"execution_count":88,"outputs":[{"name":"stdout","text":"[****************************************************************************************************]100%\nGSE44801 is over\n[****************************************************************************************************]100%\nGSE201369 is over\nconsuming: 2.660 seconds\n","output_type":"stream"}],"id":"0e198864-b263-4a97-86b9-d8dc6194cea4"}]}